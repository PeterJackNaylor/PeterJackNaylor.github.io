---
layout: post
title: ISBI 2019
description: >
  Publication in ISBI 2019 Predicting Residual Cancer Burden in a triple negative breast cancer cohort.
sitemap: false
hide_last_modified: true
---

At the ISBI 2019 held in Venice, Italy, I presented our conference paper *Predicting Residual Cancer Burden in a triple negative breast cancer cohort* during the poster session. The poster can be found [here](http://members.cbio.mines-paristech.fr/~pnaylor/Downloads/isbi_19_poster.pdf).

## Paper
The conference paper *Predicting Residual Cancer Burden in a triple negative breast cancer cohort* by *Peter Naylor, Joseph Boyd, Marick La√©, Fabien Reyal and Thomas Walter* has been published in *Biomedical Imaging (ISBI 2019)*, 2019 IEEE 16th International Symposium on (pp. 933-937).

## Data not available
The data used for the study is not available and constituted of 122 biopsy samples scanned at the Institut Curie. 
Each patient within this cohort followed this procedure:

![](/assets/img/posts/isbi2019/TNBC_pipeline.png){:class="img-responsive"}
**Figure 1**: *Data generation pipeline at Institut Curie* 

Before treatment, we perform needle-core biopsy samples from triple negative breast cancer patients. 

After treatment, we perform a surgery to have a better idea of the residual cancer within the patient (in the primary site and axillary lymph nodes) and report a RCB score which is the variable we wish to predict. This continuous variable can be categorised into four types corresponding to four degrees of severity: pCR (56), RCB-I (10), RCB-II (49) and RCB-III (7), we aim at predicting two task: (1) Prognostic pCR-RCB-I vs RCB-II-III and (2) Residual pCR vs RCB-I-II-III. 

## Summary of the paper
We note 3 contributions:
1) Existence of signal for the prediction of treatment response to chemotherapy in triple negative breast cancer, 60% accuracy on these tasks.
2) Novel model for WSI predictions: two steps and one step model.
3) Better tile invariance encoding

### Patient encoding

For each sample, we segment the tissue, we divide the available tissue into tiles and we encode the tiles with a ResNet:


![](/assets/img/posts/isbi2019/tissue_encoding.png){:class="img-responsive"}
**Figure 3**: *From the slide to a bag of encoded tiles* 
<ol type="a">
  <li>Needle-core biopsy section</li>
  <li>Tiling the available tissue</li>
  <li>Bag of tiles</li>
  <li>Bag of encoded tiles</li>
</ol>

While encoding our histopathological tiles, we notice some undesired source of noise, specifically encoding variances to image transformation such as flip. These types of transformation should not affect the underlying encoding for histology data as there is no natural orientation given to the tile.
![](/assets/img/posts/isbi2019/encoding_variance.png){:class="img-responsive"}
**Figure 4**: *Encoding variances for histological images* 

<ol type="a">
  <li>Input image</li>
  <li>Flipped input image by the *Flip* augmentation</li>
  <li>Encoding of the input image by the ResNet encoder *NN*</li>
  <li>Encoding of the flipped input image</li>
</ol>
We notice different scales in the encoding but also in different areas. This is due to the pre-training on ImageNet where the samples have a natural orientation.
We propose three different encodings:

- None, solely *NN(.)*
- Max, for one image, we generated its encoding for several basic transformations (identity, flip, rotation, ...), for this image's final encoding, we take the max for each index over the encoded transformation.
- Mean, same idea as Max expect we take the mean per index.

### Results: 

![](/assets/img/posts/isbi2019/table_results_TNBC.png){:class="img-responsive"}
**Table 1**: *Table of results on task (1) and (2), measure by accuracy with a 10-nested cross validation*.

In the 2 step method, Uniform and K-means denote the down-sampling procedure used for the tile cluster model training.

### Models:
We compare 4 types of models:
#### Manual feature extraction
Model based on pathological relevant features extracted manually from each tissue. On top of these 5 extracted variables we put a random forest on top.

Example of manual extracted features:

![](/assets/img/posts/isbi2019/mitose_count.png){:class="img-responsive"}
**Figure 5**: *Mitotic index* 

![](/assets/img/posts/isbi2019/cancer_count.png){:class="img-responsive"}
**Figure 6**: *Cancer cellularity* 

#### Two step model

![](/assets/img/posts/isbi2019/2S_idea.png){:class="img-responsive"}
**Figure 7**: *Two step method idea* 
<ol type="a">
  <li>Needle-core biopsy section</li>
  <li>Tiling the available tissue</li>
  <li>Bag of tiles</li>
  <li>Clustering model training</li>
  <li>Tile cluster assignment</li>
  <li>Needle-core biopsy section encoding</li>
  <li>Needle-core biopsy classification</li>
</ol>

![](/assets/img/posts/isbi2019/2S_practice.png){:class="img-responsive"}
**Figure 8**: *Two step method in practice* 
<ol type="a">
  <li>Needle-core biopsy section</li>
  <li>Tiling the available tissue</li>
  <li>Bag of tiles</li>
  <li>Clustering model training</li>
  <li>Tile cluster assignment</li>
  <li>Needle-core biopsy section encoding</li>
  <li>Needle-core biopsy classification</li>
</ol>

#### One step model
![](/assets/img/posts/isbi2019/one_step.png){:class="img-responsive"}
**Figure 8**: *One step method* 
<ol type="a">
  <li>Needle-core biopsy section</li>
  <li>Tiling the available tissue</li>
  <li>Bag of tiles</li>
  <li>Bottleneck neural network layer, reducing each tile encoding to a smaller encoding</li>
  <li>Continuous tile cluster assignment</li>
  <li>Mean pooling followed by two classification layers for needle-core biopsy section classification.</li>
</ol>
Parts d., e. and f. were separated in the two step model, they are now unified via a neural network.

#### Bag averaging
We simply encode the needle-core biopsy section by the average tile encoding and then fit a random forest on top.



## Conlusion
The best model is the unified approach with the mean encoding.
